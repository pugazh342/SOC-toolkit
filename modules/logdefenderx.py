# BlueDefenderX/modules/logdefenderx.py
import re
import os
import json
from datetime import datetime
from utils.logger import bd_logger

class LogDefenderX:
    def __init__(self, config_path="config/rules.yaml"): # Basic config for future use
        self.config_path = config_path
        self.parsed_logs = []
        self.parsers = {
            'ssh': self.parse_ssh_log,
            'generic': self.parse_generic_log,
            # Add more parsers here as needed (e.g., 'apache', 'nginx')
            # Add the endpoint telemetry parser
            'endpoint': self.parse_endpoint_telemetry,
        }
        bd_logger.info("LogDefenderX initialized.")

    def read_log_file(self, file_path):
        """Reads a log file line by line."""
        if not os.path.exists(file_path):
            bd_logger.error(f"Log file not found: {file_path}")
            return []

        logs = []
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    logs.append(line.strip())
            bd_logger.info(f"Read {len(logs)} lines from {file_path}")
            return logs
        except Exception as e:
            bd_logger.error(f"Error reading log file {file_path}: {e}")
            return []

    def parse_ssh_log(self, log_line):
        """Parses a typical SSH log line."""
        # Example line: Jan 10 10:00:00 server sshd[1234]: Failed password for invalid user admin from 192.168.1.100 port 54321 ssh2
        # More robust pattern
        pattern = r'(\w{3}\s+\d{1,2}\s+\d{2}:\d{2}:\d{2})\s+(\S+)\s+sshd(?:\[\d+\])?:\s+(.*)'
        match = re.search(pattern, log_line)
        if match:
            timestamp_str, hostname, message = match.groups()
            # Extract IP
            ip_pattern = r'from\s+(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'
            ip_match = re.search(ip_pattern, message)
            src_ip = ip_match.group(1) if ip_match else None

            # Determine event type based on message content
            event_type = "unknown"
            if "Failed password" in message:
                event_type = "ssh_failed_login"
            elif "Accepted password" in message or "Accepted publickey" in message:
                event_type = "ssh_successful_login"
            elif "Disconnected" in message:
                event_type = "ssh_disconnect"
            elif "Invalid user" in message:
                event_type = "ssh_invalid_user"

            return {
                "timestamp": timestamp_str, # Simplified, needs full datetime parsing
                "hostname": hostname,
                "service": "sshd",
                "event_type": event_type,
                "message": message,
                "src_ip": src_ip,
                "raw": log_line
            }
        return None

    def parse_generic_log(self, log_line):
        """Placeholder for generic log parsing."""
        # A very basic parser, can be expanded
        parts = log_line.split(' ', 4) # Split into max 5 parts
        if len(parts) >= 5:
            return {
                "timestamp": parts[0] + " " + parts[1] + " " + parts[2],
                "hostname": parts[3],
                "message": parts[4],
                "raw": log_line
            }
        else:
            return {"message": log_line, "raw": log_line}

    def parse_endpoint_telemetry(self, file_path):
        """
        Parses telemetry data generated by EndpointAgent from a JSONL file.

        Args:
            file_path (str): Path to the endpoint_telemetry.jsonl file.

        Returns:
            list: A list of dictionaries, each representing a parsed telemetry entry.
        """
        if not os.path.exists(file_path):
            bd_logger.error(f"Endpoint telemetry file not found: {file_path}")
            return []

        parsed_entries = []
        try:
            with open(file_path, 'r') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        entry = json.loads(line)
                        # Add a simple 'event_type' tag for consistency
                        entry['event_type'] = 'endpoint_telemetry'
                        # Add raw line for reference if needed
                        entry['raw'] = line
                        parsed_entries.append(entry)
                    except json.JSONDecodeError as e:
                        bd_logger.warning(f"Error decoding JSON on line {line_num} of {file_path}: {e}")
            bd_logger.info(f"Parsed {len(parsed_entries)} entries from endpoint telemetry file {file_path}")
        except Exception as e:
            bd_logger.error(f"Error reading endpoint telemetry file {file_path}: {e}")

        return parsed_entries

    def parse_logs(self, logs, log_type="generic"):
        """Parses a list of log lines."""
        parsed = []
        # Handle file-based parsing for 'endpoint' type
        if log_type == 'endpoint':
             # 'logs' parameter is expected to be the file path string for endpoint telemetry
             if isinstance(logs, str): # Check if logs is actually a file path string
                 parsed = self.parse_endpoint_telemetry(logs)
             else:
                 bd_logger.error("For 'endpoint' log type, 'logs' parameter should be the file path string.")
                 parsed = []
        else:
            # Handle line-by-line parsing for other types
            parser_func = self.parsers.get(log_type, self.parse_generic_log)
            
            for line in logs:
                try:
                    parsed_event = parser_func(line)
                    if parsed_event:
                        parsed.append(parsed_event)
                except Exception as e:
                    bd_logger.error(f"Error parsing line with {log_type} parser: {line[:100]}... Error: {e}")

        self.parsed_logs.extend(parsed)
        bd_logger.info(f"Parsed {len(parsed)} log events (type: {log_type}).")
        return parsed

    def get_parsed_logs(self):
        """Returns the list of parsed logs."""
        return self.parsed_logs

# Example usage for testing (inside if __name__ == '__main__': block)
if __name__ == '__main__':
    ld = LogDefenderX()

    # --- Test SSH Log Parsing ---
    print("--- Testing SSH Log Parsing ---")
    # Create a sample log file for testing
    sample_logs = [
        "Jan 10 10:00:00 server sshd[1234]: Failed password for invalid user admin from 192.168.1.100 port 54321 ssh2",
        "Jan 10 10:01:00 server sshd[1235]: Accepted password for user1 from 10.0.0.1 port 22 ssh2",
        "Jan 10 10:02:00 webserver apache2: 192.168.1.50 - - [10/Jan/2024:10:02:00 +0000] \"GET /index.html HTTP/1.1\" 200 1234",
        "Generic log message without standard format"
    ]
    with open("sample_ssh.log", "w") as f:
        for log in sample_logs:
            f.write(log + "\n")

    raw_logs = ld.read_log_file("sample_ssh.log")
    parsed_ssh = ld.parse_logs(raw_logs, log_type="ssh")
    for log in parsed_ssh:
        print(log) # Or use logger

    parsed_generic = ld.parse_logs(["Generic message 1", "Generic message 2"], log_type="generic")
    print("\n--- Testing Generic Log Parsing ---")
    for log in parsed_generic:
        print(log)

    # --- Test Endpoint Telemetry Parsing ---
    print("\n--- Testing Endpoint Telemetry Parsing ---")
    # Parse the endpoint telemetry file generated by EndpointAgent
    # Option 1: Using parse_logs with 'endpoint' type (passing the file path)
    parsed_endpoint_logs = ld.parse_logs("sample_endpoint_data.jsonl", log_type="endpoint")
    print(f"Parsed {len(parsed_endpoint_logs)} endpoint telemetry entries using parse_logs:")
    # --- FIX: Use the correct variable name in the loop ---
    for entry in parsed_endpoint_logs: # Iterate over the parsed entries
        print(f"  Host: {entry.get('host')}, Event Type: {entry.get('event_type')}")
    # --- END FIX ---

    # Option 2: Using the dedicated method directly (passing the file path)
    print("\n--- Testing Endpoint Telemetry Parsing (Direct Method) ---")
    parsed_endpoint_logs_direct = ld.parse_endpoint_telemetry("sample_endpoint_data.jsonl")
    print(f"Parsed {len(parsed_endpoint_logs_direct)} endpoint telemetry entries using parse_endpoint_telemetry directly:")
    for entry in parsed_endpoint_logs_direct: # Iterate over the parsed entries
        # Access nested data
        sys_info = entry.get('system_info', {})
        print(f"  Host: {entry.get('host')}, CPU: {sys_info.get('cpu_percent')}%, Memory: {sys_info.get('memory_percent')}%")

    # Clean up sample files
    import os
    sample_files = ["sample_ssh.log"] # Note: EndpointAgent created sample_endpoint_data.jsonl
    for file in sample_files:
        if os.path.exists(file):
            os.remove(file)
            print(f"\nCleaned up temporary file: {file}")
    # Clean up the file created by EndpointAgent test
    endpoint_file = "sample_endpoint_data.jsonl"
    if os.path.exists(endpoint_file):
        os.remove(endpoint_file)
        print(f"Cleaned up EndpointAgent file: {endpoint_file}")
